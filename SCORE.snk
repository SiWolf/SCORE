# ---------------------------------------------------------------------------
# Title: SCORE
# Author: Silver A. Wolf
# Last Modified: Wed, 31.10.2018
# Version: 0.4.6
# Usage:
#		time snakemake -s "SCORE.snk" -j {max_amount_of_threads} --use-conda
# Additional options:
#		sequanix
#       snakemake -s "SCORE.snk" -n
#       snakemake -s "SCORE.snk" --config {parameter}={value}
#       snakemake -s "SCORE.snk" --forceall --dag | dot -Tsvg > dag.svg
# ---------------------------------------------------------------------------

# Imports
import csv

# Specifying the config file
configfile: "config.yaml"

# Global parameters
METADATA = config["metadata_file"]
PARAM_DEG_BAYSEQ = config["bayseq_threshold"]
PARAM_DEG_GENERAL = config["general_threshold"]
PARAM_DEG_WEIGHT_BAYSEQ = config["weight_bayseq"]
PARAM_DEG_WEIGHT_DESEQ2 = config["weight_deseq2"]
PARAM_DEG_WEIGHT_EDGER = config["weight_edger"]
PARAM_DEG_WEIGHT_LIMMA = config["weight_limma"]
PARAM_DEG_WEIGHT_NOISEQ = config["weight_noiseq"]
PARAM_FLEXBAR_LENGTH = config["flexbar_min_length"]
PARAM_FLEXBAR_QUAL = config["flexbar_min_qual"]
PARAM_FLEXBAR_UNCALLED = config["flexbar_max_uncalled"]
PARAM_GENESCF_GO_DB = config["genescf_go_db"]
PARAM_GENESCF_KEGG_DB = config["genescf_kegg_db"]
PARAM_GENESCF_TOTAL_GENES_SPECIES = config["genescf_total_genes_species"]
PATH_FLEXBAR = config["flexbar_path"]
PATH_GENESCF = config["geneSCF_path"]
REF_ANNOTATION = config["ref_annotation_file"]
REF_ANNOTATION_FEATURE_ID = config["ref_annotation_feature_type"]
REF_ANNOTATION_GENE_ID = config["ref_annotation_gene_type"]
REF_FASTA = config["ref_fasta_file"]
REF_INDEX = config["ref_index_name"]

# Functions
def fetch_annotation(gff_file, annotation_feature):
	consensus_extended = open("deg/consensus_diffexpr_results_extended.csv", "w") 
	with open("deg/consensus_diffexpr_results.csv") as consensus_results:
		for consensus_line in csv.reader(consensus_results, delimiter = ","):
			direction = ""
			gene = ""
			product = ""
			id = consensus_line[0]
			if id == "":
				consensus_extended.write("ID,gene name,product," + consensus_line[1] + "," + consensus_line[2] + "," + consensus_line[3] + "," + consensus_line[4] + "," + consensus_line[5] + ",ordering\n")
			else:
				with open(gff_file) as gff_annotation:
					for gff_line in csv.reader(gff_annotation, delimiter = "\t"):
						if len(gff_line) > 8 and gff_line[2] == annotation_feature:
							current_id = gff_line[8].split("ID=")[1].split(";")[0]
							if id == current_id:
								product = gff_line[8].split("product=")[1]
								if gff_line[8].split("ID=")[1].count("gene=") > 0:
									gene = gff_line[8].split("gene=")[1].split(";")[0]
								break
				with open("deg/bayseq_diffexpr_results_extended.csv") as bayseq_results:
					for bayseq_line in csv.reader(bayseq_results, delimiter = ","):
						if id == bayseq_line[0]:
							direction = bayseq_line[9]
							break
				consensus_extended.write(consensus_line[0] + "," + gene + "," + product + "," + consensus_line[1] + "," + consensus_line[2] + "," + consensus_line[3] + "," + consensus_line[4] + "," + consensus_line[5] + "," + direction + "\n")
	consensus_extended.close()

def fetch_gene_symbols(new_file):
	list_of_gene_symbols = open(new_file, "w")
	with open("deg/consensus_diffexpr_results_extended.csv") as consensus_list:
		for line in csv.reader(consensus_list, delimiter = ","):
			if line[1] != "":
				list_of_gene_symbols.write(line[1].split("_")[0] + "\n")
	list_of_gene_symbols.close()

def read_tsv(tsv_filename):
	samples_dic = {}
	with open("raw/" + tsv_filename) as tsv:
		for line in csv.reader(tsv, delimiter = "\t"):
			if line[0][0] != "@":
				samples_dic[line[0]] = line[1]
	return(samples_dic)

# Samples
SAMPLES_AND_CONDITIONS = read_tsv(METADATA)
SAMPLES = SAMPLES_AND_CONDITIONS.keys()

# GeneSCF 1.1-p2
# Runs a pathway and GO term overrepresentation analysis on the DEG list
# TO-DO: Test different GO and KEGG dbs
rule pathway_analysis:
	input:
		"deg/deg_gene_symbols.csv"
	output:
		"deg/pathway_analysis_GO",
		"deg/pathway_analysis_KEGG"
	shell:
		"""
		mkdir -p {output[0]}
		mkdir -p {output[1]}		
		{PATH_GENESCF} -m=update -i={input} -t=sym -o={output[0]} -db=GO_all -p=yes -bg={PARAM_GENESCF_TOTAL_GENES_SPECIES} -org={PARAM_GENESCF_GO_DB}
		{PATH_GENESCF} -m=update -i={input} -t=sym -o={output[1]} -db=KEGG -p=yes -bg={PARAM_GENESCF_TOTAL_GENES_SPECIES} -org={PARAM_GENESCF_KEGG_DB}
		"""

rule DEG_postprocessing:
	input:
		"deg_analysis_graphs.pdf"
	output:
		"deg/deg_gene_symbols.csv"
	run:
		# Move result graphs file to other output files
		shell("mv {input} deg/")
		# Fetching initial annotations
		fetch_annotation(REF_ANNOTATION, REF_ANNOTATION_FEATURE_ID)
		# Create a list of gene symbols for the DEGs
		fetch_gene_symbols(output[0])

# baySeq 2.14.0
# DESeq2 1.20.0
# edgeR 3.22.5
# limma 3.36.5
# NOISeq 2.24.0
rule DEG_analysis:
	input:
		expand("mapped/bowtie2/featureCounts/{sample}/", sample = SAMPLES)
	output:
		"deg_analysis_graphs.pdf"
	conda:
		"libraries/score_deg_environment.yml"
	shell:
		"""
		# Fetch transcript lengths using another python script
		python libraries/fetch_transcript_lengths.py -f {REF_ANNOTATION} -i {REF_ANNOTATION_GENE_ID}
		# Idea: Rscript <folder>/SCORE.R <SAMPLES>
		Rscript libraries/SCORE.R {METADATA} {PARAM_DEG_BAYSEQ} {PARAM_DEG_GENERAL} {PARAM_DEG_WEIGHT_BAYSEQ} {PARAM_DEG_WEIGHT_DESEQ2} {PARAM_DEG_WEIGHT_EDGER} {PARAM_DEG_WEIGHT_LIMMA} {PARAM_DEG_WEIGHT_NOISEQ}
		"""
		
# featureCounts 1.6.2
# Counts mapped reads to genomic features
# Needed for the quantification of Bowtie2 results
# Discards multi-mapping reads by default
# TO-DO: Break iff 0 counts in total! (Warning else?)
rule counting:
	input:
		"mapped/bowtie2/{sample}.sam"
	output:
		"mapped/bowtie2/featureCounts/{sample}/"
	conda:
		"libraries/score_count_environment.yml"
	threads:
		4
	shell:
		"""
		featureCounts -T {threads} -a {REF_ANNOTATION} -o counts_{wildcards.sample} {input} -t {REF_ANNOTATION_FEATURE_ID} -g {REF_ANNOTATION_GENE_ID}
		mv counts_{wildcards.sample}* {output}
		"""

# Bowtie2 2.3.4.3
# Creates a reference index for each genome
# Performs an ungapped genome mapping
# Bowtie2 allows up to 2 mismatches (default)
# Moves the alignment reference index file afterwards, since it's not used anymore
# Followed by quanitification of transcripts (counting of reads)
# TO-DO: Verify that mapping went well?
rule mapping:
	input:
		"trimmed/{sample}_trimmed_1.fastq.gz",
		"trimmed/{sample}_trimmed_2.fastq.gz"
	output:
		"mapped/bowtie2/{sample}.sam"
	conda:
		"libraries/score_map_environment.yml"
	threads:
		4
	shell:
		"""
		bowtie2-build {REF_FASTA} {REF_INDEX}_{wildcards.sample}
		bowtie2 -q --phred33 -p {threads} --no-unal -x {REF_INDEX}_{wildcards.sample} -1 {input[0]} -2 {input[1]} -S {output}
		rm {REF_INDEX}_{wildcards.sample}*
		"""

# FastQC 0.11.7
# Flexbar 3.4.0
# Quality control and basequality trimming
# TO-DO: Should not forget adapter trimming when using new data!
# TO-DO: Create Conda environment for Flexbar
rule quality_control_and_trimming:
	input:
		"raw/{sample}_1.fastq.gz",
		"raw/{sample}_2.fastq.gz"
	output:
		"trimmed/{sample}_trimmed_1.fastq.gz",
		"trimmed/{sample}_trimmed_2.fastq.gz"
	conda:
		"libraries/score_qc_environment.yml"
	log:
		"trimmed/logs/"
	threads:
		4
	shell:
		"""
		# Initial FastQC
		mkdir -p fastqc/{wildcards.sample}/
		fastqc {input} -o fastqc/{wildcards.sample}/
		# Trimming
		{PATH_FLEXBAR} -r {input[0]} -p {input[1]} -t {wildcards.sample}_trimmed -n {threads} -u {PARAM_FLEXBAR_UNCALLED} -q TAIL -qf sanger -qt {PARAM_FLEXBAR_QUAL} -m {PARAM_FLEXBAR_LENGTH} -z GZ
		mv {wildcards.sample}_trimmed_1.fastq.gz trimmed/
		mv {wildcards.sample}_trimmed_2.fastq.gz trimmed/
		mv {wildcards.sample}_trimmed.log {log}
		mkdir -p fastqc/{wildcards.sample}_trimmed/
		# Second FastQC
		fastqc trimmed/{wildcards.sample}_trimmed_1.fastq.gz -o fastqc/{wildcards.sample}_trimmed/
		fastqc trimmed/{wildcards.sample}_trimmed_2.fastq.gz -o fastqc/{wildcards.sample}_trimmed/
		"""
		
onstart:
	print("\n Welcome to SCORE: Smart Consensus Of RNA-Seq Expression pipelines")
	print(" Please ensure all input files are located within the raw/ folder and your parameters have been set accordingly.")		
		
onerror:
	print("\n It seems like something went wrong. Please refer to the error messages listed above for additional information. \n")

onsuccess:
	print("\n SCORE finished successfully. \n")