# ---------------------------------------------------------------------------
# Title: SCORE
# Author: Silver A. Wolf
# Last Modified: Fr, 05.10.2018
# Version: 0.3.7
# Usage:
#		time snakemake -s "SCORE.snk" -j {max_amount_of_threads} --use-conda
# Additional options:
#		sequanix
#       snakemake -s "SCORE.snk" -n
#       snakemake -s "SCORE.snk" --dag | dot -Tsvg > dag.svg
#       snakemake -s "SCORE.snk" --config {parameter}={value}
# ---------------------------------------------------------------------------

# Imports
import csv

# Specifying the config file
configfile: "config.yaml"

# Global parameters
METADATA = config["metadata_file"]
PARAM_DEG_BAYSEQ = config["bayseq_threshold"]
PARAM_DEG_GENERAL = config["general_threshold"]
PARAM_DEG_WEIGHT_BAYSEQ = config["weight_bayseq"]
PARAM_DEG_WEIGHT_DESEQ2 = config["weight_deseq2"]
PARAM_DEG_WEIGHT_EDGER = config["weight_edger"]
PARAM_DEG_WEIGHT_LIMMA = config["weight_limma"]
PARAM_DEG_WEIGHT_NOISEQ = config["weight_noiseq"]
PARAM_FLEXBAR_LENGTH = config["flexbar_min_length"]
PARAM_FLEXBAR_QUAL = config["flexbar_min_qual"]
PARAM_FLEXBAR_UNCALLED = config["flexbar_max_uncalled"]
PATH_FLEXBAR = config["flexbar_path"]
REF_ANNOTATION = config["ref_annotation_file"]
REF_ANNOTATION_FEATURE_ID = config["ref_annotation_feature_type"]
REF_ANNOTATION_GENE_ID = config["ref_annotation_gene_type"]
REF_FASTA = config["ref_fasta_file"]
REF_INDEX = config["ref_index_name"]

# Functions
def fetch_annotation(gff_file, annotation_feature):
	consensus_extended = open("deg/consensus_diffexpr_results_extended.csv", "w") 
	with open("deg/consensus_diffexpr_results.csv") as consensus_results:
		for consensus_line in csv.reader(consensus_results, delimiter = ","):
			direction = ""
			gene = ""
			product = ""
			id = consensus_line[0]
			if id == "":
				consensus_extended.write("ID,gene name,product," + consensus_line[1] + "," + consensus_line[2] + "," + consensus_line[3] + ",ordering\n")
			else:
				with open(gff_file) as gff_annotation:
					for gff_line in csv.reader(gff_annotation, delimiter = "\t"):
						if len(gff_line) > 8 and gff_line[2] == annotation_feature:
							current_id = gff_line[8].split("ID=")[1].split(";")[0]
							if id == current_id:
								product = gff_line[8].split("product=")[1]
								if gff_line[8].split("ID=")[1].count("gene=") > 0:
									gene = gff_line[8].split("gene=")[1].split(";")[0]
								break
				with open("deg/bayseq_diffexpr_results_extended.csv") as bayseq_results:
					for bayseq_line in csv.reader(bayseq_results, delimiter = ","):
						if id == bayseq_line[0]:
							direction = bayseq_line[9]
							break
				consensus_extended.write(consensus_line[0] + "," + gene + "," + product + "," + consensus_line[1] + "," + consensus_line[2] + "," + consensus_line[3] + "," + direction + "\n")
	consensus_extended.close()

def read_tsv(tsv_filename):
	samples_dic = {}
	with open("raw/" + tsv_filename) as tsv:
		for line in csv.reader(tsv, delimiter = "\t"):
			if line[0][0] != "@":
				samples_dic[line[0]] = line[1]
	return(samples_dic)

# Samples
SAMPLES_AND_CONDITIONS = read_tsv(METADATA)
SAMPLES = SAMPLES_AND_CONDITIONS.keys()

rule postprocessing:
	input:
		"deg_analysis_graphs.pdf"
	output:
		"deg/deg_analysis_graphs.pdf"
	run:
		# Move result graphs file to other output files
		shell("mv {input} deg/")
		# Fetching initial annotations
		fetch_annotation(REF_ANNOTATION, REF_ANNOTATION_FEATURE_ID)

# baySeq Version 2.12.0
# DESeq2 Version 1.18.1
# edgeR Version 3.20.7
# limma Version 3.34.9
rule DEG_analysis:
	input:
		expand("mapped/bowtie2/featureCounts/{sample}/", sample = SAMPLES)
	output:
		"deg_analysis_graphs.pdf"
	conda:
		"libraries/score_deg_environment.yml"
	shell:
		"""
		# Fetch transcript lengths using another python script
		python libraries/fetch_transcript_lengths.py -f {REF_ANNOTATION} -i {REF_ANNOTATION_GENE_ID}
		# Idea: Rscript <folder>/SCORE.R <SAMPLES>
		Rscript libraries/SCORE.R {METADATA} {PARAM_DEG_BAYSEQ} {PARAM_DEG_GENERAL} {PARAM_DEG_WEIGHT_BAYSEQ} {PARAM_DEG_WEIGHT_DESEQ2} {PARAM_DEG_WEIGHT_EDGER} {PARAM_DEG_WEIGHT_LIMMA} {PARAM_DEG_WEIGHT_NOISEQ}
		"""
		
# featureCounts Version 1.6.2
# Counts mapped reads to genomic features
# Needed for the quantification of Bowtie2 results
# Discards multi-mapping reads by default
# TO-DO: Break iff 0 counts in total! (Warning else?)
rule counting:
	input:
		"mapped/bowtie2/{sample}.sam"
	output:
		"mapped/bowtie2/featureCounts/{sample}/"
	conda:
		"libraries/score_count_environment.yml"
	threads:
		4
	shell:
		"""
		featureCounts -T {threads} -a {REF_ANNOTATION} -o counts_{wildcards.sample} {input} -t {REF_ANNOTATION_FEATURE_ID} -g {REF_ANNOTATION_GENE_ID}
		mv counts_{wildcards.sample}* {output}
		"""

# Bowtie2 Version 2.3.4.3
# Creates a reference index for each genome
# Performs an ungapped genome mapping
# Moves the alignment reference index file afterwards, since it's not used anymore
# Followed by quanitification of transcripts (counting of reads)
# TO-DO: Verify that mapping went well?
# TO-DO: Verify parallelization
rule mapping:
	input:
		"trimmed/{sample}_trimmed_1.fastq.gz",
		"trimmed/{sample}_trimmed_2.fastq.gz"
	output:
		"mapped/bowtie2/{sample}.sam"
	conda:
		"libraries/score_map_environment.yml"
	threads:
		4
	shell:
		"""
		bowtie2-build {REF_FASTA} {REF_INDEX}_{wildcards.sample}
		bowtie2 -q --phred33 -p {threads} --no-unal -x {REF_INDEX}_{wildcards.sample} -1 {input[0]} -2 {input[1]} -S {output}
		rm {REF_INDEX}_{wildcards.sample}*
		"""

# FastQC Version 0.11.7
# Flexbar Version 3.3.0
# Quality control and basequality trimming
# TO-DO: Should not forget adapter trimming when using new data!
# TO-DO: Create Conda environment for Flexbar
rule quality_control_and_trimming:
	input:
		"raw/{sample}_1.fastq.gz",
		"raw/{sample}_2.fastq.gz"
	output:
		"trimmed/{sample}_trimmed_1.fastq.gz",
		"trimmed/{sample}_trimmed_2.fastq.gz"
	conda:
		"libraries/score_qc_environment.yml"
	log:
		"trimmed/logs/"
	threads:
		4
	shell:
		"""
		# Initial FastQC
		mkdir -p fastqc/{wildcards.sample}/
		fastqc {input} -o fastqc/{wildcards.sample}/
		# Trimming
		{PATH_FLEXBAR} -r {input[0]} -p {input[1]} -t {wildcards.sample}_trimmed -n {threads} -u {PARAM_FLEXBAR_UNCALLED} -q TAIL -qf sanger -qt {PARAM_FLEXBAR_QUAL} -m {PARAM_FLEXBAR_LENGTH} -z GZ
		mv {wildcards.sample}_trimmed_1.fastq.gz trimmed/
		mv {wildcards.sample}_trimmed_2.fastq.gz trimmed/
		mv {wildcards.sample}_trimmed.log {log}
		mkdir -p fastqc/{wildcards.sample}_trimmed/
		# Second FastQC
		fastqc trimmed/{wildcards.sample}_trimmed_1.fastq.gz -o fastqc/{wildcards.sample}_trimmed/
		fastqc trimmed/{wildcards.sample}_trimmed_2.fastq.gz -o fastqc/{wildcards.sample}_trimmed/
		"""
		
onstart:
	print("\n Welcome to SCORE: Smart Consensus Of RNA-Seq Expression pipelines")
	print(" Please ensure all input files are located within the raw/ folder and your parameters have been set accordingly.")		
		
onerror:
	print("\n Something went wrong. Please refer to the error messages listed above. \n")

onsuccess:
	print("\n SCORE finished successfully. \n")